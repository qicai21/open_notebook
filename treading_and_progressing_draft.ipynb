{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "sound-arrival",
   "metadata": {},
   "source": [
    "- title: python多进程多线程抓取图片\n",
    "- author: Burgan\n",
    "- date: 2021-02-19\n",
    "- category: Projects\n",
    "- tags: python, crawler\n",
    "- status: draft\n",
    "- summary: 使用多进程+多线程方式爬区图片的简单实现\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "varying-cheat",
   "metadata": {},
   "source": [
    "多进程多线程的资料一大把, 这里简单推荐几个,可供参考:\n",
    "\n",
    "[Multiprocessing : use tqdm to display a progress bar](https://stackoverflow.com/questions/41920124/multiprocessing-use-tqdm-to-display-a-progress-bar)\n",
    "\n",
    "[Python ThreadPoolExecutor Tutorial](https://tutorialedge.net/python/concurrency/python-threadpoolexecutor-tutorial/)\n",
    "\n",
    "[python 彻底解读多线程与多进程](https://blog.csdn.net/lzy98/article/details/88819425)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "hindu-building",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ttl import\n",
    "import os\n",
    "import time\n",
    "from random import random, randint\n",
    "from pathlib import Path\n",
    "import json\n",
    "import requests\n",
    "from threading import Thread\n",
    "from multiprocessing import Process, Pool, Manager\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "import datetime\n",
    "from concurrent.futures import ThreadPoolExecutor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abandoned-campus",
   "metadata": {},
   "source": [
    "## Step_1: 将页面url按规则计算出来,存在一个dict中,{url, file_path, saved}, 并设有检查器"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cheap-stroke",
   "metadata": {},
   "source": [
    "**初始化并保存数据表, 保存到'./urls_data.json'**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "pleasant-animation",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_vol_url():\n",
    "    vol_dict = dict()\n",
    "    res = requests.get('https://www.manhuadb.com/manhua/222/211_2669.html')\n",
    "    soup = BeautifulSoup(res.content, 'lxml')\n",
    "    links = soup.find_all('li', 'sort_div')\n",
    "    def append_by_li(li):\n",
    "        vol_ = 'vol_' + li['data-sort']\n",
    "        vol_dict[vol_] = 'https://www.manhuadb.com'+li.a['href']\n",
    "    [append_by_li(li) for li in links]\n",
    "    return vol_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "roman-conviction",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_image_count_of_vol(vol_url):\n",
    "    res = requests.get(vol_url)\n",
    "    soup = BeautifulSoup(res.content, 'lxml')\n",
    "    div = soup.find('div', {'class': {'d-none vg-r-data'}, })\n",
    "    return int(div['data-total'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "weekly-lithuania",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_vol_df(vol, url):\n",
    "    \"\"\"把一个vol的页码完型并存到df中.\"\"\"\n",
    "    counts = get_image_count_of_vol(url)\n",
    "    img_urls = [url.replace('.html', '_p%d.html' % i) for i in range(1, counts+1)]\n",
    "    def set_path_by_no(no):\n",
    "        folder = f'/home/qicai21/Pictures/blames/{vol}/'\n",
    "        name = '{0:03}.jpg'.format(no)\n",
    "        return folder + name\n",
    "    img_paths = [set_path_by_no(i) for i in range(1, counts+1)]\n",
    "    exists = np.zeros(counts, dtype=int)\n",
    "    vols = np.repeat(vol, counts)\n",
    "    df = pd.DataFrame({\n",
    "        'url': img_urls,\n",
    "        'path': img_paths,\n",
    "        'exist': exists,\n",
    "        'vol': vols\n",
    "\n",
    "    })\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "certified-hybrid",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_all_img_data():\n",
    "    vols = get_all_vol_url()\n",
    "    dfs = [get_vol_df(vol, url) for vol, url in vols.items()]\n",
    "    return pd.concat(dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "further-kitty",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = set_all_img_data()\n",
    "df = df.reset_index(drop=True)\n",
    "df.to_json('./urls_data.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "certified-essex",
   "metadata": {},
   "source": [
    "**update数据表的exist选项**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "hybrid-annex",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_exist(data_row):\n",
    "    p = Path(data_row['path'])\n",
    "    if not p.parents[0].exists():\n",
    "        p.parents[0].mkdir(parents=True, exist_ok=True)\n",
    "    if p.exists():\n",
    "        data_row['exist'] = 1\n",
    "    return data_row\n",
    "        \n",
    "def update_img_df_with_file_exist(df):\n",
    "    return df.apply(set_exist, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "gorgeous-corruption",
   "metadata": {},
   "outputs": [],
   "source": [
    "read_df = pd.read_json('./urls_data.json')\n",
    "df = update_img_df_with_file_exist(read_df)\n",
    "df.to_json('./urls_data.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "obvious-parcel",
   "metadata": {},
   "source": [
    "## Step_2: 简单线程用例"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "annoying-prerequisite",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start check file /home/qicai21/Pictures/blames/vol_1/001.jpg\n",
      "exist\n",
      "start check file /home/qicai21/Pictures/blames/vol_1/051.jpg\n",
      "exist\n",
      "start check file /home/qicai21/Pictures/blames/vol_1/101.jpg\n",
      "exist\n",
      "start check file /home/qicai21/Pictures/blames/vol_1/151.jpg\n",
      "exist\n",
      "start check file /home/qicai21/Pictures/blames/vol_1/201.jpg\n",
      "exist\n",
      "start check file /home/qicai21/Pictures/blames/vol_1/251.jpg\n",
      "exist\n",
      "start check file /home/qicai21/Pictures/blames/vol_2/050.jpg\n",
      "not exist\n",
      "start check file /home/qicai21/Pictures/blames/vol_2/100.jpg\n",
      "not exist\n",
      "start check file /home/qicai21/Pictures/blames/vol_2/150.jpg\n",
      "not exist\n",
      "start check file /home/qicai21/Pictures/blames/vol_2/200.jpg\n",
      "not exist\n",
      "start check file /home/qicai21/Pictures/blames/vol_3/027.jpg\n",
      "not exist\n",
      "start check file /home/qicai21/Pictures/blames/vol_3/077.jpg\n",
      "not exist\n",
      "start check file /home/qicai21/Pictures/blames/vol_3/127.jpg\n",
      "not exist\n",
      "start check file /home/qicai21/Pictures/blames/vol_3/177.jpg\n",
      "not exist\n",
      "start check file /home/qicai21/Pictures/blames/vol_3/227.jpg\n",
      "not exist\n",
      "start check file /home/qicai21/Pictures/blames/vol_4/034.jpg\n",
      "not exist\n",
      "start check file /home/qicai21/Pictures/blames/vol_4/084.jpg\n",
      "not exist\n",
      "start check file /home/qicai21/Pictures/blames/vol_4/134.jpg\n",
      "not exist\n",
      "start check file /home/qicai21/Pictures/blames/vol_4/184.jpg\n",
      "not exist\n",
      "start check file /home/qicai21/Pictures/blames/vol_5/017.jpg\n",
      "not exist\n",
      "tasks completed!\n"
     ]
    }
   ],
   "source": [
    "def delay_check_file(path):\n",
    "    print('start check file %s' % path)\n",
    "    time.sleep(random())\n",
    "    if Path(path).exists():\n",
    "        print('exist')\n",
    "    else:\n",
    "        print('not exist')\n",
    "\n",
    "def make_thread(row):\n",
    "    t = Thread(target=delay_check_file, args=(row['path'],))\n",
    "    t.start()\n",
    "    t.join()\n",
    "        \n",
    "df = read_df\n",
    "df[0:1000:50].apply(make_thread, axis=1)\n",
    "print('tasks completed!')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "expired-cambridge",
   "metadata": {},
   "source": [
    "## Step_3: 封装下载方法为线程方法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "presidential-academy",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "download complete!\n"
     ]
    }
   ],
   "source": [
    "def download_image(url, path_to_save):\n",
    "    res = requests.get(url)\n",
    "    soup = BeautifulSoup(res.content, 'lxml')\n",
    "    img = soup.find('img', {'class': {'img-fluid show-pic'}, })\n",
    "    src = img['src']\n",
    "    res = requests.get(src)\n",
    "    with open(path_to_save, 'wb') as file:\n",
    "        file.write(res.content)\n",
    "\n",
    "def generate_download_thread(url, path):\n",
    "    t = Thread(target=download_image, args=(url, path))\n",
    "    t.start()\n",
    "    return t\n",
    "\n",
    "url_list = read_df[read_df['vol']=='vol_3']['url'][:10].tolist()\n",
    "path_list = read_df[read_df['vol']=='vol_3']['path'][:10].tolist()\n",
    "tasks = [generate_download_thread(url, path) for url, path in zip(url_list, path_list)]\n",
    "[t.join() for t in tasks]\n",
    "print('download complete!')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "neural-transaction",
   "metadata": {},
   "source": [
    "## Step_4: 简单进程用例"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bronze-restriction",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start check file /home/qicai21/Pictures/blames/vol_2/001.jpg\n",
      "start check file /home/qicai21/Pictures/blames/vol_3/001.jpg\n",
      "7168: exist\n",
      "start check file /home/qicai21/Pictures/blames/vol_2/051.jpg\n",
      "7168: exist\n",
      "start check file /home/qicai21/Pictures/blames/vol_2/101.jpg\n",
      "7171: not exist\n",
      "start check file /home/qicai21/Pictures/blames/vol_3/051.jpg\n",
      "7168: exist\n",
      "start check file /home/qicai21/Pictures/blames/vol_2/151.jpg\n",
      "7171: not exist\n",
      "start check file /home/qicai21/Pictures/blames/vol_3/101.jpg\n",
      "7171: not exist\n",
      "start check file /home/qicai21/Pictures/blames/vol_3/151.jpg\n",
      "7168: exist\n",
      "start check file /home/qicai21/Pictures/blames/vol_2/201.jpg\n",
      "7171: not exist\n",
      "start check file /home/qicai21/Pictures/blames/vol_3/201.jpg\n",
      "7168: exist\n",
      "7171: not exist\n",
      "task completed!\n"
     ]
    }
   ],
   "source": [
    "def delay_check_file(path):\n",
    "    print('start check file %s' % path)\n",
    "    time.sleep(random())\n",
    "    if Path(path).exists():\n",
    "        print(f'{os.getpid()}: exist')\n",
    "    else:\n",
    "        print(f'{os.getpid()}: not exist')\n",
    "        \n",
    "        \n",
    "read_df = pd.read_json('./urls_data.json')\n",
    "p_list_2 = read_df[read_df['vol'] == 'vol_2'][::50]['path'].tolist()\n",
    "p_list_3 = read_df[read_df['vol'] == 'vol_3'][::50]['path'].tolist()\n",
    "\n",
    "def loop_check(path_list):\n",
    "    [delay_check_file(p) for p in path_list]\n",
    "    \n",
    "p1 = Process(target=loop_check, args=(p_list_2, ))\n",
    "p2 = Process(target=loop_check, args=(p_list_3, ))\n",
    "\n",
    "p1.start()\n",
    "p2.start()\n",
    "p1.join()\n",
    "p2.join()\n",
    "print('task completed!')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bridal-conditions",
   "metadata": {},
   "source": [
    "## Step_5: 封装下载方法为多进程方法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "lovely-tobacco",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in thread Thread-141:\n",
      "Exception in thread Traceback (most recent call last):\n",
      "Thread-157  File \"/home/qicai21/anaconda3/lib/python3.8/site-packages/urllib3/connectionpool.py\", line 699, in urlopen\n",
      ":\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/qicai21/anaconda3/lib/python3.8/site-packages/urllib3/connectionpool.py\", line 699, in urlopen\n",
      "    httplib_response = self._make_request(\n",
      "      File \"/home/qicai21/anaconda3/lib/python3.8/site-packages/urllib3/connectionpool.py\", line 445, in _make_request\n",
      "httplib_response = self._make_request(\n",
      "      File \"/home/qicai21/anaconda3/lib/python3.8/site-packages/urllib3/connectionpool.py\", line 445, in _make_request\n",
      "six.raise_from(e, None)\n",
      "      File \"<string>\", line 3, in raise_from\n",
      "six.raise_from(e, None)  File \"/home/qicai21/anaconda3/lib/python3.8/site-packages/urllib3/connectionpool.py\", line 440, in _make_request\n",
      "\n",
      "      File \"<string>\", line 3, in raise_from\n",
      "httplib_response = conn.getresponse()  File \"/home/qicai21/anaconda3/lib/python3.8/site-packages/urllib3/connectionpool.py\", line 440, in _make_request\n",
      "\n",
      "  File \"/home/qicai21/anaconda3/lib/python3.8/http/client.py\", line 1347, in getresponse\n",
      "    httplib_response = conn.getresponse()\n",
      "      File \"/home/qicai21/anaconda3/lib/python3.8/http/client.py\", line 1347, in getresponse\n",
      "response.begin()\n",
      "      File \"/home/qicai21/anaconda3/lib/python3.8/http/client.py\", line 307, in begin\n",
      "response.begin()\n",
      "  File \"/home/qicai21/anaconda3/lib/python3.8/http/client.py\", line 307, in begin\n",
      "    version, status, reason = self._read_status()    \n",
      "version, status, reason = self._read_status()  File \"/home/qicai21/anaconda3/lib/python3.8/http/client.py\", line 276, in _read_status\n",
      "\n",
      "      File \"/home/qicai21/anaconda3/lib/python3.8/http/client.py\", line 276, in _read_status\n",
      "raise RemoteDisconnected(\"Remote end closed connection without\"\n",
      "http.client    .raise RemoteDisconnected(\"Remote end closed connection without\"RemoteDisconnected\n",
      ": Remote end closed connection without responsehttp.client.\n",
      "RemoteDisconnected\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      ": Traceback (most recent call last):\n",
      "Remote end closed connection without response  File \"/home/qicai21/anaconda3/lib/python3.8/site-packages/requests/adapters.py\", line 439, in send\n",
      "\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "    resp = conn.urlopen(  File \"/home/qicai21/anaconda3/lib/python3.8/site-packages/requests/adapters.py\", line 439, in send\n",
      "\n",
      "  File \"/home/qicai21/anaconda3/lib/python3.8/site-packages/urllib3/connectionpool.py\", line 755, in urlopen\n",
      "    resp = conn.urlopen(    \n",
      "retries = retries.increment(  File \"/home/qicai21/anaconda3/lib/python3.8/site-packages/urllib3/connectionpool.py\", line 755, in urlopen\n",
      "\n",
      "  File \"/home/qicai21/anaconda3/lib/python3.8/site-packages/urllib3/util/retry.py\", line 573, in increment\n",
      "    retries = retries.increment(\n",
      "      File \"/home/qicai21/anaconda3/lib/python3.8/site-packages/urllib3/util/retry.py\", line 573, in increment\n",
      "raise MaxRetryError(_pool, url, error or ResponseError(cause))    \n",
      "raise MaxRetryError(_pool, url, error or ResponseError(cause))\n",
      "urllib3.exceptions.urllib3.exceptionsMaxRetryError.: MaxRetryErrorHTTPSConnectionPool(host='i2.manhuadb.com', port=443): Max retries exceeded with url: /ccbaike/211/2670/127_sibhgjon.jpg (Caused by ProxyError('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response'))): \n",
      "HTTPSConnectionPool(host='i2.manhuadb.com', port=443): Max retries exceeded with url: /ccbaike/211/2670/143_dwfgfkrz.jpg (Caused by ProxyError('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response')))\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "\n",
      "Traceback (most recent call last):\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "  File \"/home/qicai21/anaconda3/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
      "Traceback (most recent call last):\n",
      "      File \"/home/qicai21/anaconda3/lib/python3.8/threading.py\", line 932, in _bootstrap_inner\n",
      "    self.run()self.run()\n",
      "\n",
      "  File \"/home/qicai21/anaconda3/lib/python3.8/threading.py\", line 870, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"<ipython-input-18-cb7eb4aac771>\", line 6, in download_image\n",
      "  File \"/home/qicai21/anaconda3/lib/python3.8/threading.py\", line 870, in run\n",
      "      File \"/home/qicai21/anaconda3/lib/python3.8/site-packages/requests/api.py\", line 76, in get\n",
      "self._target(*self._args, **self._kwargs)\n",
      "      File \"<ipython-input-18-cb7eb4aac771>\", line 6, in download_image\n",
      "return request('get', url, params=params, **kwargs)  File \"/home/qicai21/anaconda3/lib/python3.8/site-packages/requests/api.py\", line 76, in get\n",
      "\n",
      "  File \"/home/qicai21/anaconda3/lib/python3.8/site-packages/requests/api.py\", line 61, in request\n",
      "        return request('get', url, params=params, **kwargs)return session.request(method=method, url=url, **kwargs)\n",
      "\n",
      "  File \"/home/qicai21/anaconda3/lib/python3.8/site-packages/requests/api.py\", line 61, in request\n",
      "  File \"/home/qicai21/anaconda3/lib/python3.8/site-packages/requests/sessions.py\", line 542, in request\n",
      "    resp = self.send(prep, **send_kwargs)\n",
      "  File \"/home/qicai21/anaconda3/lib/python3.8/site-packages/requests/sessions.py\", line 655, in send\n",
      "        return session.request(method=method, url=url, **kwargs)r = adapter.send(request, **kwargs)\n",
      "  File \"/home/qicai21/anaconda3/lib/python3.8/site-packages/requests/sessions.py\", line 542, in request\n",
      "\n",
      "  File \"/home/qicai21/anaconda3/lib/python3.8/site-packages/requests/adapters.py\", line 510, in send\n",
      "    resp = self.send(prep, **send_kwargs)    raise ProxyError(e, request=request)\n",
      "\n",
      "  File \"/home/qicai21/anaconda3/lib/python3.8/site-packages/requests/sessions.py\", line 655, in send\n",
      "requests.exceptions.    ProxyErrorr = adapter.send(request, **kwargs): \n",
      "HTTPSConnectionPool(host='i2.manhuadb.com', port=443): Max retries exceeded with url: /ccbaike/211/2670/127_sibhgjon.jpg (Caused by ProxyError('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response')))  File \"/home/qicai21/anaconda3/lib/python3.8/site-packages/requests/adapters.py\", line 510, in send\n",
      "\n",
      "    raise ProxyError(e, request=request)\n",
      "requests.exceptions.ProxyError: HTTPSConnectionPool(host='i2.manhuadb.com', port=443): Max retries exceeded with url: /ccbaike/211/2670/143_dwfgfkrz.jpg (Caused by ProxyError('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response')))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pid[9339]: all tread completed\n",
      "pid[9340]: all tread completed\n",
      "all download completed!\n"
     ]
    }
   ],
   "source": [
    "vol3_df = read_df[read_df['vol']=='vol_3'].loc[:, ['url', 'path']]\n",
    "imgs = vol3_df.values.tolist()\n",
    "\n",
    "def download_threading(imgs):\n",
    "    threads = [Thread(target=download_image, args=(url, path)) for url, path in imgs]\n",
    "    [t.start() for t in threads]\n",
    "    [t.join() for t in threads]\n",
    "    print('pid[%s]: all tread completed' % os.getpid())\n",
    "     \n",
    "p1 = Process(target=download_threading, args=(imgs[:171],))\n",
    "p2 = Process(target=download_threading, args=(imgs[171:],))\n",
    "p1.start()\n",
    "p2.start()\n",
    "    \n",
    "p1.join()\n",
    "p2.join()\n",
    "print('all download completed!')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "macro-tokyo",
   "metadata": {},
   "source": [
    "> 这个过程之中有2个线程抛出了异常,但程序并未中止.查看了一下,错误来自于图片服务器没有响应,requests不再等待了.\n",
    "\n",
    ">\"\n",
    "raise ProxyError(e, request=request)\n",
    "requests.exceptions.ProxyError: HTTPSConnectionPool(host='i2.manhuadb.com', port=443): Max retries exceeded with url: /ccbaike/211/2670/143_dwfgfkrz.jpg (Caused by ProxyError('Cannot connect to proxy.', RemoteDisconnected('Remote end closed connection without response')))\"\n",
    "\n",
    ">当然,如果说这2,300的并发访问就给服务器带来什么压力的话,不太现实,但直观感受是这样有点用力过猛.\n",
    ">必须知道的是:在2019年05月28日国家网信办发布的《数据安全管理办法（征求意见稿）》中，拟通过行政法规的形式，对爬虫的使用进行限制：\n",
    "\n",
    ">\"\n",
    "第十六条 网络运营者采取自动化手段访问收集网站数据，不得妨碍网站正常运行；此类行为严重影响网站运行，如自动化访问收集流量超过网站日均流量三分之一，网站要求停止自动化访问收集时，应当停止。\n",
    "\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "approved-facility",
   "metadata": {},
   "source": [
    "## Step_6: 封装线程方法到2个进程中"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "fluid-skirt",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting ThreadPoolExecutor\n",
      "loop start\n",
      "Processing 0\n",
      "Processing 1\n",
      "Processing 2\n",
      "loop start\n",
      "Processing 3\n",
      "Processing 4\n",
      "Processing 5\n",
      "All tasks complete\n"
     ]
    }
   ],
   "source": [
    "# python3.2后增加了原生的线程池的支持,有说法是max_workers默认为5,但是在文档里没查到.手动指定一下更安全.\n",
    "\n",
    "\n",
    "def task(n):\n",
    "    if n%3==0:\n",
    "        print(\"loop start\")\n",
    "    print(\"Processing {}\".format(n))\n",
    "       \n",
    "def pool_run():\n",
    "    print(\"Starting ThreadPoolExecutor\")\n",
    "    with ThreadPoolExecutor(max_workers=3) as executor:\n",
    "        [executor.submit(task, (i)) for i in range(6)]\n",
    "    print(\"All tasks complete\")\n",
    "    \n",
    "pool_run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "welcome-survival",
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_img_in_30s(url, path_to_save):\n",
    "    try:\n",
    "        res = requests.get(url, timeout=30)\n",
    "        soup = BeautifulSoup(res.content, 'lxml')\n",
    "        img = soup.find('img', {'class': {'img-fluid show-pic'}, })\n",
    "        src = img['src']\n",
    "        try:\n",
    "            res = requests.get(src, timeout=30)\n",
    "            with open(path_to_save, 'wb') as file:\n",
    "                file.write(res.content)\n",
    "        except Exception as e:\n",
    "            return\n",
    "    except Exception as e:\n",
    "        return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "blind-plastic",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def run_download_threads(imgs):\n",
    "    print(\"pro_%s: start\" % os.getpid())\n",
    "    with ThreadPoolExecutor(max_workers=5) as exec:\n",
    "        [exec.submit(download_img_in_30s, *i) for i in imgs]\n",
    "    print(\"pro_%s: completed\" % os.getpid())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "confirmed-polyester",
   "metadata": {},
   "outputs": [],
   "source": [
    "read_df = pd.read_json('./urls_data.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "moved-emperor",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "####################\n",
      "loop start: 04:19:00\n",
      "pro_23290: start\n",
      "pro_23293: start\n",
      "pro_23293: completed\n",
      "pro_23290: completed\n",
      "loop finish: 04:21:30\n"
     ]
    }
   ],
   "source": [
    "df = update_img_df_with_file_exist(read_df)\n",
    "imgs = df[df['exist']==0][:400].loc[:, ['url', 'path']].values.tolist()\n",
    "print(\"#\"*20)\n",
    "print(\"loop start: %s\" % datetime.datetime.now().strftime('%H:%M:%S'))\n",
    "p1 = Process(target=run_download_threads, args=(imgs[:200], ))\n",
    "p2 = Process(target=run_download_threads, args=(imgs[200:], ))\n",
    "p1.start()\n",
    "p2.start()\n",
    "p1.join()\n",
    "p2.join()\n",
    "print(\"loop finish: %s\" % datetime.datetime.now().strftime('%H:%M:%S'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "purple-donna",
   "metadata": {},
   "source": [
    "> 这里就出了一个奇奇怪怪的问题,executor.submit执行的参数,如果数量大于1个程序就不执行,但*号传进去就没问题..."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
